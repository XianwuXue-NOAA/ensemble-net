#!/usr/bin/env python3
#
# Copyright (c) 2017-18 Jonathan Weyn <jweyn@uw.edu>
#
# See the file LICENSE for your rights.
#

"""
Trains and tests an ensemble selection model using predictors generated by ens_sel_batch_process.py. Implements an
'online learning' scheme whereby chunks of the data are loaded dynamically and training occurs on these individual
chunks.
"""

from ensemble_net.util import save_model
from ensemble_net.ensemble_selection import preprocessing, model, verify
import numpy as np
import pandas as pd
import time
import xarray as xr
import os


def process_chunk(ds, ):
    forecast_predictors, fpi = preprocessing.convert_ensemble_predictors_to_samples(ds['ENS_PRED'].values,
                                                                                    convolved=convolved)
    ae_predictors, epi = preprocessing.convert_ae_meso_predictors_to_samples(ds['AE_PRED'].values, convolved=convolved)
    ae_targets, eti = preprocessing.convert_ae_meso_predictors_to_samples(ds['AE_TAR'].values, convolved=convolved)
    combined_predictors = preprocessing.combine_predictors(forecast_predictors, ae_predictors)

    # Remove samples with NaN
    if impute_missing:
        p, t = combined_predictors, ae_targets
    else:
        p, t = preprocessing.delete_nan_samples(combined_predictors, ae_targets)

    return p, t


# Paths to important files
root_data_dir = '%s/Data/ensemble-net' % os.environ['WORKDIR']
predictor_file = '%s/predictors_201504-201603_28N43N100W80W_x4_no_c.nc' % root_data_dir
model_file = '%s/selector_201504-201603_no_c' % root_data_dir
convolved = False


# Copy file to scratch space
copy_file_to_scratch = False


# Neural network configuration and options
chunk_size = 10
batch_size = 50
epochs_per_chunk = 10
loops = 4
impute_missing = True
val_set = 'first'
val_size = 5
# Use multiple GPUs
n_gpu = 1


# Load a Dataset with the predictors
predictor_ds = xr.open_dataset(predictor_file, mask_and_scale=True)
num_dates = predictor_ds.ENS_PRED.shape[0]


# Get dimensionality for formatted predictors/targets and a validation set
if val_set == 'first':
    predictor_ds.isel(init_date=range(val_size))
elif val_set == 'last':
    predictor_ds.isel(init_date=slice(num_dates - val_size, None, None))
else:
    raise ValueError("'val_set' must be 'first' or 'last'")
p_val, t_val = process_chunk(predictor_ds)
input_shape = p_val.shape[1:]
num_outputs = t_val.shape[1]


# Build an ensemble selection model
print('Building an EnsembleSelector model...')
selector = model.EnsembleSelector(impute_missing=impute_missing)
layers = (
    # ('Conv2D', (64,), {
    #     'kernel_size': (3, 3),
    #     'activation': 'relu',
    #     'input_shape': input_shape
    # }),
    ('Dense', (1024,), {
        'activation': 'relu',
        'input_shape': input_shape
    }),
    ('Dropout', (0.25,), {}),
    ('Dense', (num_outputs,), {
        'activation': 'relu'
    }),
    ('Dropout', (0.25,), {}),
    ('Dense', (num_outputs,), {
        'activation': 'linear'
    })
)
selector.build_model(layers=layers, gpus=n_gpu, loss='mse', optimizer='adam', metrics=['mae'])


# Create chunks
if val_set == 'first':
    start = val_size
    end = num_dates
else:
    start = 0
    end = num_dates - val_size
chunks = []
index = 1 * start
while index < num_dates:
    chunks.append(slice(index, index + chunk_size))
    index += chunk_size


# Do the online training
# Train and evaluate the model
print('Training the EnsembleSelector model...')
start_time = time.time()
for loop in range(loops):
    print('  Loop %d of %d' % (loop+1, loops))
    for chunk in range(len(chunks)):
        print('    Data chunk %d of %d' % (chunk+1, len(chunks)))
        predictors, targets = (None, None)
        predictor_ds.isel(init_date=chunks[chunk])
        predictors, targets = process_chunk(predictor_ds)
        selector.fit(predictors, targets, batch_size=batch_size, epochs=epochs_per_chunk, verbose=1,
                     validation_data=(p_val, t_val))

end_time = time.time()

score = selector.evaluate(p_val, t_val, verbose=0)
print("\nTrain time -- %s seconds --" % (end_time - start_time))
print('Test loss:', score[0])
print('Test mean absolute error:', score[1])

if model_file is not None:
    save_model(selector, model_file)
